\section{Evaluation}

\label{sec:evaluation}

In this section we shall begin by reflecting on some of the successes of the
project, followed by suggestions of improvements that could be made to our
implementation were we to have more time. We conclude with a reflection on the
project as a whole.

\subsection{Successes}

One obvious success of the project is that we have implemented the
decentralised prediction market that we originally intended based on the work
of Freeman et al. A key component of the market is that participants are
incentivised to act in the desired way through paying each user a specific
amount of money. This has required building a strong understanding of their
paper to ensure everything has been implemented correctly so that we may
achieve the theoretical guarantees that they outline.  We have also managed to
become more well-acquainted with the wider literature on prediction markets; a
key goal motivation before choosing a project had been to gain more exposure to
the field of algorithmic game theory, and in this regard the project has been a
personal success.

Translating the mechanism Freeman et al.\ from a theoretical setting into a
practical environment has required slightly modifying certain aspects of it to
make it functional in the real world, especially with respect to the
assumptions we can make. For example, the paper uses the following bound on the
number of securities to calculate the minimum payment required in the
arbitration stage to incentivise truth-telling:
%
\begin{equation}
	\label{eq:kBoundB}
	k \ge \frac{2 B (1+f)}{f m \delta}
\end{equation}
%
in which $B$ is the maximum amount of money that any single agent can spend in
the market. They use the above inequality instead of
inequality~\eqref{eq:kBoundN} as they view knowledge about an upper bound on
the number of securities that any single agent owns, $|n_i|$, as ``an
unsatisfying restriction''. However, since we are the prediction market, we
require knowledge about each agent's position in order to pay out winnings
appropriately by the time the event has taken place.  Hence we can use
inequality~\eqref{eq:kBoundN} to calculate the minimum value of $k$, giving a
more direct means of computing the parameter and a more exact bound.

Another modification we make is in our calculation of what we have referred to
as a user's ``positive signal belief'' and ``negative signal belief''. These
are so named because in an earlier version of the market, each time an arbiter
was asked to report on an event's outcome they would be asked for an estimation
of $\Pr[x_i=1|X=1]$, the probability that they receive a positive signal given
the true result is positive; and $\Pr[x_i=1|X=0]$, the probability that they
receive a positive signal given the event was truly negative. Freeman et al.\
assume knowledge of the news sources from which users gain their signals -- for
example, for some political event it is known that 10\% of the population
checks only liberal or left-leaning news sources, while 10\% check only
right-leaning sources. These signal probabilities therefore directly follow. In
practice this is completely unrealistic, since users may check a variety of
news sources at varying points on the political spectrum, so we cannot know
from where exactly which proportions of the population are getting their
information. Instead, we compute the signal beliefs using each arbiter's
reporting history and the true outcomes of the events they have reported on.
This gives us an idea of the signal each arbiter receives on average. However,
this value will not change from market to market, meaning we are less
well-equipped to deal with ambiguous wagers since an arbiter has no way to
signify to the system that the bet was indeed unclear or open to
interpretation. Having the value of $\delta$, the ``update strength'', vary
between markets allows the $k$ from equation~\eqref{eq:oneOverPrior} adjust
payments according to its perceived ambiguity. This issue is, however, somewhat
mitigated by the likelihood that most bets submitted on our market will be
unambiguous in nature.

One final variation that we make to the original mechanism is that we keep the
trading fee $f$ fixed. The reason for this is twofold: firstly, it relies on
$\delta$, which as we have just discussed does not vary for different markets
as it is always calculated from an arbiter's history for \emph{every} market.
If our value of $\delta$ is just an estimate, it can be argued there is little
sense in trying to set $f$ as precisely as possible. Secondly, we have not yet
been able to calculate $f$ dynamically in the allotted time. Its calculation
involves other variables and would likely require changes to various other
parts of the system, in particular the database, which could jeopardise the
system's current working state before submission. At any rate, this is
something we wish to implement in the future as, regardless of how much
$\delta$ changes, it guarantees that the mechanism generates enough revenue to
pay arbiters without requiring outside subsidisation. We currently have $f$ set
to 5\% as Freeman et al.\ show empirically that this relatively high fee can
subsidise ambiguous markets with low values of $\delta$ and high participation.
However, since it is not set dynamically, there is no way of knowing whether it
will be enough to cover arbitration costs -- only once we find ourselves paying
out more than we have will we know we have made a mistake. We can avert this
crisis by overestimating the value of $f$ required, which is the solution we
currently opt for, but this is certainly a less satisfying solution. Overall,
we consider our implementation a success as the tweaks we make to the mechanism
allow it to be realised in a practical setting that does not require
unrealistic assumptions to be made.

Finally, while not necessarily important from an academic perspective, we
consider the project a success for having been implemented in the Lisp
programming language, with which we had had no experience prior to starting the
project. It has at times rendered development more challenging and introduced
obstacles that would not have ordinarily been there -- for example, worrying
about whether a Parenscript and Smackjack statement would translate to the
correct JavaScript, as opposed to simply writing the correct JavaScript
straight away -- although the features of the language have also made it a more
rewarding experience. In addition to harnessing the power of macros, its
functional style along with its simple, consistent syntax has oftentimes
allowed for the code to be written in a clearer, more concise manner.

\subsection{Next steps}

\subsubsection{Additions}

There are numerous improvements we can make to our market, and while we have
implemented all necessary features of the paper on which we base the mechanism
itself, such additions would be significant in increasing the usability of our
system. These fall into two categories: those that add new functionality, and
those that improve on the existing codebase.

A key feature missing from the system currently is the ability to plot graphs
of a market's share price. This would greatly improve the usability of the
system and would be an effective analytical tool to visualise a security's
price movements over time. Since share price is a proxy for the community's
beliefs on the outcome of the corresponding event, this would be useful in
observing how public sentiment changes throughout a market's lifetime as a
result of the agents receiving new information. It appears there is plenty of
choice regarding libraries that would allow one to plot such graphs, such as
ADW-Charting and CGN, which are both available through Quicklisp.

One way to generalise the mechanism we have implemented would be to allow for
different types of events to be wagered on. Currently, users may only submit
events whose outcome is either a ``yes'' or a ``no'' -- this could be improved
upon by allowing for categorical markets, in which traders are offered to buy
or sell shares in more than two mutually exclusive outcomes. For example, a
market could be created on the bet, ``Which country will host the 2032 Olympic
Games'', with options to invest in Germany, Italy, the United States, and
Canada. There are two issues with this that prevented it from being explored
within the time-frame of this project. Firstly, a great deal of the analysis of
\cite{Freeman2017} relies on the assumption that traders are participating in a
binary market, hence much of the parameters would have to be derived again in
order to successfully translate the incentive-compatible mechanism to the
categorical setting. While this is feasible over a longer period, the idea came
too late to be possible in the remaining time. Secondly, the codebase would
need to be altered significantly to allow for this generalisation. It could be
beneficial, since binary markets are just subsets of categorical ones, however
the system would require a large rewrite to generate the HTML dynamically and
deal with the added complexity.

Finally, a longer term goal would be to apply the approaches of Kroer et
al.~\cite{Kroer2016} to our market to translate it to a combinatorial setting.
However, the extent to which this can be done appears to be very limited: a key
component of the mechanisms they analyse is that the securities are related in
some way, meaning a user's participation in one security can affect the odds of
another. The degree to which a new security is related to other existing
securities is controlled by the market creator, who for example sets the
initial price and specifies the constraints used in solving the integer
programs. This would be counter-productive in our setting since we rely on
users to create the markets themselves: either we allow users to control these
parameters, in which case we must incentivise them to act truthfully, or we
specify them ourselves, which may be inaccurate and negates the point of
implementing a decentralised market in the first place.

With more time, we would also look to implement more responsiveness from the 
system. This would include building on the JavaScript code already in place to
have prices constantly updating, so that users are informed of price changes as
they happen and they may execute trades at these up-to-date prices. Similarly,
countdowns for markets whose deadlines are imminent would be useful in not only
making the interface feel more alive but also in generating urgency and
encouraging user participation.

\subsubsection{Improvements}

Currently we allow any user to create a market for an event of their choosing.
We require that upon creating the market, they are only able to buy
shares. This is a natural restriction that means users only make markets for
events they believe will, more than likely, occur. However, there is nothing to
stop them from simply negating the statement and creating a market for this.
Although not a serious issue, this may lead to unnatural or unclear phrasing,
in which case it would simply be better to allow them to go short initially.
An issue related to this is that we do not verify the bets that users place,
and therefore there could be duplicate markets on the same event whose prices
do not match. Clearly buyers are encouraged to trade in the lower priced one,
and sellers the higher priced one, leading to a discrepancy in the forecasts we
make. We do not currently see a good solution to this problem.

An issue in our implementation is that of deciding when there are enough
reports. Instead of randomly selecting users to act as arbiters, which may
cause delays in determining the outcome of the market as we must wait for each
arbiter to report, we allow any user to act as an arbiter, hopefully increasing
the speed with which we can close markets. Thanks to how we set the parameter
$k$ in equation~\eqref{eq:oneOverPrior}, arbiters are incentivised to act
truthfully regardless of whether they hold a stake in the market. However, it
is undecided how the number of arbiters required should scale with the size of
the userbase: it is currently set to two for ease of testing, though it will
somehow need to increase with a growing community (up to a point). This in turn
allows for finer control over the payout per share.

Finally, there are several sources of avoidable inefficiency in our code.
Firstly, consider the fragments given in Listing~\ref{lst:reportingHistory}.
In order to get a user's reporting history we first retrieve all of the
securities reported on by the user from the \code{SECURITY} table, then we
iterate over these returned securities and retrieve the securities whose
outcome has been determined: this involves executing one query for each parent
record and another for each child record. This is known as the $N+1$ query
problem and is common among ORMs such as Mito. We can achieve equivalent
behaviour for a fraction of the queries using eager loading, which executes a
single query to retrieve each child record. Mito has a specific macro for this,
and given this pattern's prevalence in our codebase, would make for a useful
improvement. We use our \code{with-open-database} macro, given in
Listing~\ref{lst:databaseMacro}, to define many of the functions exposed by the
database interface. Problems of inefficiency could arise when calling numerous
of these functions sequentially, since a connection would be opened and closed
for each one. It would be more efficient to connect only once, execute all
transactions, and then disconnect. At present, we do not see a solution to this
that keeps the benefits of macroising the interactions with the database in the
first place.

\subsection{Closing Remarks}

Overall, this project has been successful and we have enjoyed building an
understanding of the literature surrounding prediction markets, as well as
gaining proficiency in Lisp. One criticism of the project is that it does not
necessarily offer something new, since we base our design on an existing
mechanism in order to achieve their guarantees. While we implement the peer
prediction market and make necessary adaptations to make it suitable for
real-world use, there are no novel results that arise from our work. The
alternative, of proving some new theoretical result, would of course have been
an unlikely task in the time frame, although the project could have perhaps
benefited from being more ambitious. At any rate, what we implement here can be
used as an effective tool to calculate forecasts on a wide array of bets and is
open to further extension to increase the potential for real-world use.

We will leave our prediction market running for as long as possible after
submission here: \url{https://1a091f61d58d.ngrok.io/index}. Many thanks go to
Matthias for supervising this project, in suggesting to look at prediction
markets, and for helpful advice throughout.
