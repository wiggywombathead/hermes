\section{Evaluation}

\label{sec:evaluation}

In this section we shall begin by reflecting on some of the successes of the
project, followed by suggestions of improvements that could be made to our
implementation were we to have more time. We conclude with a reflection on the
project as a whole.

\subsection{Successes}

One obvious success of the project is that we have implemented the
decentralised prediction market that we originally intended based on the work
of Freeman et al. A key component of the market is that participants are
incentivised to act in the desired way through paying each user a deliberate
and calculated amount of money. This has required building a strong
understanding of their paper to ensure everything has been implemented
correctly so that we may achieve the theoretical guarantees that they outline.
We have also managed to become more well-acquainted with the wider literature
on prediction markets; a key goal motivation before choosing a project had been
to gain more exposure to the field of algorithmic game theory, and in this
regard the project has been a personal success.

Translating the mechanism Freeman et al.\ from a theoretical setting into a
practical environment has required slightly modifying certain aspects of it to
make it functional in the real world, especially with respect to the
assumptions we can make. For example, the paper uses the following bound on the
number of securities to calculate the minimum payment required in the
arbitration stage to incentivise truth-telling:
%
\begin{equation}
	\label{eq:kBoundB}
	k \ge \frac{2 B (1+f)}{f m \delta}
\end{equation}

in which $B$ is the maximum amount of money that any single agent can spend in
the market. They use this instead of Equation~\ref{eq:kBoundB} as they view
knowledge about an upper bound on the number of securities that any single
agent owns, $|n_i|$, as ``an unsatisfying restriction''. However, since we are
the prediction market, we require knowledge about each agent's position in
order to pay out winnings appropriately by the time the event has taken place.
Hence we can use Equation~\ref{eq:kBoundN} to calculate the minimum value of
$k$, giving a more direct means of computing the parameter and a more exact
bound.

Another modification we make is in our calculation of what we have referred to
as a user's ``positive signal belief'' and ``negative signal belief''. These
are so named because in an earlier version of the market, each time an arbiter
was asked to report on an event's outcome they would be asked for an estimation
of $Pr[x_i=1|X=1]$, the probability that they receive a positive signal given
the true result is positive; and $Pr[x_i=1|X=0]$, the probability that they
receive a positive signal given the event was truly negative. Freeman et al.\
assume knowledge of the news sources from which users gain their signals -- for
example, for some political event it is known that 10\% of the population
checks only liberal or left-leaning news sources, while 10\% check only
right-leaning sources. These signal probabilities therefore directly follow. In
practice this is completely unrealistic, since users may check a variety of
news sources at varying points on the political spectrum, so we cannot know
from where exactly which proportions of the population are getting their
information. Instead we compute such signal beliefs using each arbiter's
reporting history and the true outcomes of the events they have reported on.
This gives us an idea of the signal each arbiter receives on average. However,
this value will not change from market to market, meaning we are less
well-equipped to deal with ambiguous wagers since an arbiter has no way to
signify to the system that the bet was indeed unclear or open to
interpretation. Conversely, having the value of $\delta$, the ``update
strength'', vary between markets allows the $k$ from
Equation~\ref{eq:oneOverPrior} adjust payments according to the perceived
ambiguity of the market. This issue is, however, somewhat mitigated by the
likelihood that most bets submitted on our market will be unambiguous in
nature.

One final variation that we make to the original mechanism is that we keep the
trading fee $f$ fixed. The reason for this is twofold: firstly, it would rely
heavily on $\delta$, which as we have just discussed does not vary for
different markets since it is always calculated from an arbiter's history for
\emph{every} market. If our value of $\delta$ is just an estimate, it can be
argued there is little sense in trying to set $f$ as precisely as possible.
Secondly, we have not yet been able to implement a dynamic calculation of $f$
in the current allotted time. Its calculation would involve other variables,
which likely require changes to various other parts of the system, and in
particular the database, which could jeopardise the system's current working
state before submission. At any rate, this is something we wish to implement in
the future as, regardless of how much $\delta$ changes, it guarantees that the
mechanism generates enough revenue to pay arbiters without requiring outside
subsidisation. We currently have $f$ set to 5\% as Freeman et al.\ show
empirically that this relatively high fee can subsidise ambiguous markets with
low values of $\delta$ and high participation. However, since it is not set
dynamically, there is no way of knowing whether it will be enough to cover
arbitration costs -- only once we find ourselves paying out more than we have.
We can avert this crisis by overestimating the value of $f$ required, which is
the solution we currently opt for, but this is certainly a less satisfying
solution. Overall, we consider our implementation a success as the tweaks we
make to the mechanism allow it to be realised in a practical setting that not
too restrictive in the assumptions it requires.

Finally, while not necessarily important from an academic perspective, we
consider the project a success for having been implemented in the Lisp
programming language, with which we had had no experience prior to starting the
project. It has at times rendered development more challenging and introduced
obstacles that would not have ordinarily been there -- for example, worrying
about whether a Parenscript and Smackjack statement would translate to the
correct Javascript -- although the features of the language have also made it a
more rewarding experience. In addition to harnessing the power of macros, its
functional style along with its simple, consistent syntax has oftentimes
allowed for the code to be written in a clearer, more concise manner.

\subsection{Next steps}

\subsubsection{Additions}

There are numerous improvements we can make to our market, and while we have
implemented all necessary features of the paper on which we base the mechanism
itself, such additions would be significant in increasing the usability of our
system. These fall into two categories: those that add new functionality, and
those that improve on the existing codebase.

A key feature missing from the system currently is the ability to plot graphs
of a market's share price. This would greatly improve the usability of the
system and would be an effective analytical tool to visualise a security's
price movements over time. Since share price is a proxy for the community's
beliefs on the outcome of the corresponding event, this would be useful in
observing how public sentiment changes throughout a market's lifetime as a
result of the agents receiving new information. It appears there is plenty of
choice regarding libraries that would allow one to plot such graphs, such as
ADW-Charting and CGN, which are both available through Quicklisp.

One way to generalise the mechanism we have implemented would be to allow for
different types of events to be wagered on. Currently users may only submit
events whose outcome is either a ``yes'' or a ``no'' -- this could be improved
upon by allowing for categorical markets, in which traders are offered to
buy or sell shares in more than two mutually exclusive outcomes. For example, a
market could be created on the bet, ``Which country will host the 2032 Olympic Games'',
with options to invest in Germany, Italy, the United States, and Canada. There
are two issues with this that prevented it from being explored within the
time-frame of this project. Firstly, a great deal of the analysis of
\cite{Freeman2017} relies on the assumption that traders are participating in a
binary market, hence much of the parameters would have to be derived again in
order to successfully translate the incentive-compatible mechanism to the
categorical setting. While this is feasible over a longer period, the idea came
too late to be possible in the remaining time. Secondly, the codebase would
need to be altered significantly to allow for this generalisation. It could be
beneficial, since binary markets are just subsets of categorical ones, however
the system would require a large rewrite to generate the HTML dynamically and
deal with the added complexity.

Finally, a longer term goal would be to apply the approaches of Kroer et
al.~\cite{Kroer2016} to our market to translate it to a combinatorial setting.
However, the extent to which this can be done appears to be very limited: a key
component of the mechanisms they analyse is that the securities are related in
some way, meaning a user's participation in one security can affect the odds of
another. The degree to which a new security is related to other existing
securities is controlled by the market creator, who for example sets the
initial price and specifies the constraints used in solving the integer
programs. This would be counter-productive in our setting since we rely on
users to create the markets themselves: either we allow users to control these
parameters, in which case we must incentivise them to act truthfully, or we
specify them ourselves, which may be inaccurate and negates the point of
implementing a decentralised market in the first place.

With more time, we would also look to implement more responsiveness from the 
system. This would include building on the Javascript code already in place to
have prices constantly updating, so that users are informed of price changes as
they happen and they may execute trades at these up-to-date prices. Similarly,
countdowns for markets whose deadlines are imminent would be useful in not only
making the interface feel more alive but also in generating urgency and
encouraging user participation.

\subsubsection{Improvements}

Currently we allow any user to create a market for an event of their choosing.
Moreover we require that upon creating the market, they are only able to buy
shares. This is a natural restriction that means users only make markets for
events they believe will, more than likely, occur. However, there is nothing to
stop them from simply negating the statement and creating a market for this.
Although not a serious issue, this may lead to unnatural or unclear phrasing,
in which case it would simply be better to allow them to go short initially.
An issue related to this is that we do not verify the bets that users place,
and therefore there could be duplicate markets on the same event whose prices
do not match. Clearly buyers are encouraged to trade in the lower priced one,
and sellers the higher priced one, leading to a discrepancy in the forecasts we
make. We do not currently see a good solution to this problem.

An issue in our implementation is that of deciding when there are enough
reports. Instead of randomly selecting users to act as arbiters, which may
cause delays in determining the outcome of the market as we must wait for each
arbiter to report, we allow any user to act as an arbiter, hopefully increasing
the speed with which we can close markets. Moreover, by virtue of how we set
the parameter $k$ in Equation~\ref{eq:oneOverPrior}, arbiters are incentivised
to act truthfully regardless of whether they hold a stake in the market.
However, it is undecided how the number of arbiters required should
scale with the size of the userbase: it is currently set to two for ease of
testing, though it will somehow need to increase with a growing community (up
to a point). This in turn allows for finer control over the payout per share.

Finally, there are several sources of needless inefficiency in our code.
Firstly, consider the fragments given in Listing~\ref{lst:reportingHistory}.
In order to get a user's reporting history we first retrieve all of the
securities reported on by the user from the \code{SECURITY} table, then we
iterate over these returned securities and retrieve the securities whose
outcome has been determined: this involves executing one query for each parent
record and another for each child record. This is known as the $N+1$ query
problem and is common among ORMs such as Mito. We can achieve equivalent
behaviour for a fraction of the queries using eager loading, which executes a
single query to retrieve each child record. Mito has a specific macro for this,
and given this pattern's prevalence in our codebase, would make for a useful
improvement.

\subsection{Closing Remarks}

\textbf{TODO}
